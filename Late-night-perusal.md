---
title: Late night perusal
date: 2018-04-13 02:38:23
tags:
---
I've been researching a ton about AI over the past three weeks. I had no idea the breadth and depth of the current literature. However, because my mathematical knowledge is not quite on par with the competence needed to read <a href='https://arxiv.org/abs/1609.03543'><i>Logical Induction</i></a> (Garrabrant et al., 2016). So, I'm mixing some HCI (also known as human-computer interaction) into my mix tonight.


### 1 _  <a href='http://humantechnology.jyu.fi/archive/vol-13/issue-2-1/ahman/@@display-file/fullPaper/%C3%85hman.pdf'>Conceptualizing the self: A critical analysis of the self as a discursive trend in human-computer research by Ahman, 2017</a> 

This is an interesting take on the way users as individual people are described in HCI literature. In this paper, Ahman outlines his exegesis of four archetypes which characterize some eighty-eight publications.  
    <li>"Through studying the use of the term the self in HCI research literature, I identified four main approaches  to  the  self:  the  instrumental  self,  the  communicative  self,  the  emotional  self and the playful self." </li>

It would be interesting to go back to this article and see what quantitative research on cognition, perception, and self-evaluation of users is or could be strung together to help Ahman deliver a concrete thesis. Formulated as this piece is in continental philosophy, any use of empirical data to support his claims would be truly fascinating. Then the technical claims would consist of very practical feedback.

Total time spent on this article: ~25 minutes; obviously not enough to do it justice. It's pretty long and the author is pretty verbose; I don't have the attention span to look into all of the literary sources cited to parse empirical information therein. I like the article, though, and, again, I hope to return to it one day.



### 2 _ <a href='https://www.eller.arizona.edu/sites/mis/files/documents/speakers-series/2016/mis_speakrs_series_joe_valachich_2.pdf'>How is your user feeling? Inferring emotion through human-computer interaction devices by Hibbeln, Jenkins, Schneider, Valacich, and Weinmann, 2017</a> 


Interesting results from this study. I'm keen to think more about how UI and UX could become a dynamic process such that the system adjusts itself according to patterns of user behavior. 

A segment from the abstract outlines its immediate utility in my aforementioned considerations:

   <li>We report three studies. In Study 1, an experiment with 65 participants from Amazon’s Mechanical Turk, we randomly manipulated negative emotion and then monitored participants’ mouse cursor movements as they completed a number-ordering task. We found that negative emotion increases the distance and  reduces  the speed of mouse cursor movements during the task. In Study 2, an experiment  with 126 participants  from  a  U.S.  university,  we randomly manipulated  negative emotion  and then  monitored participants’ mouse cursor movements while they interacted with a mock e-commerce site.  We found that mouse cursor distance  and  speed can  be  used to infer the presence  of negative emotion  with an overall accuracy rate of 81.7 percent. In Study 3, an observational study with 80 participants from universities inGermany and Hong Kong, we monitored mouse cursor movements while participants interacted with an online product configurator. Participants reported their level of emotion after each step in the configuration process. We found that mouse cursor distance and speed can be used to infer the level of negative emotion with an out-of-sample R^2 of 0.17."
</li>


### 3_ Other interesting papers / AI-related included

<a href='https://cacm.acm.org/magazines/2017/9/220442-technical-perspective-humans-and-computers-working-together-on-hard-tasks/abstract'>Humans and Computers Working Together on Hard Tasks by Chi, 2017 </a>
"While  we continue to   explore the boundary of what is possible for machine intelligence, we should also be exploring the boundary of how humans will interact with machine  intelligence."

<a href='https://nlp.stanford.edu/~manning/papers/p46-green.pdf'>Natural language translation at the intersection of AI and HCI by Green, Heer, and Manning, 2015</a>

<a href='https://www2.deloitte.com/content/dam/Deloitte/us/Documents/deloitte-analytics/us-deloitte-analytics-hbr-ai-for-the-real-world.pdf'>Artificial intelligence for the real world: don't start with moon shots by Davenport and Ronanki, 2018</a>

<a href='https://web.eecs.umich.edu/~wlasecki/pubs/scribe_cacm2017.pdf'>Scribe: Deep integration of human and machine intelligence to caption speech in real time by Lasecki, Miller, Naim, Kushalnagar, Sadilek, Gildea, and Birgham, 2017</a>

<a href='https://www.tandfonline.com/doi/full/10.1080/10447318.2015.1064638'>Toward a taxonomy of affective computing by Schwark, 2015</a> also, see <a href='https://affect.media.mit.edu/publications.php'>MIT Affective Computing Group</a>

<a href='https://onlinelibrary.wiley.com/doi/abs/10.1111/1468-0394.00151'>Intelligent interaction design: the role of human-computer interaction research in the design of intelligent systems by Blandford, 2002</a>