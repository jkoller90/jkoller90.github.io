<p><a href="http://gamesfromwithin.com/data-oriented-design">http://gamesfromwithin.com/data-oriented-design</a></p>
<p>Data-Oriented Design (Or Why You Might Be Shooting Yourself in The Foot With OOP) by Llopis, 2009 </p>
<p>&quot;The culprit? Random memory access patterns and constant cache misses. &quot;</p>
<h3 id="with-regards-to-procedural-programming-and-oop-">With regards to Procedural Programming and OOP:</h3>
<p>&quot;Notice that the main focus of both approaches is code: plain procedures (or functions) in one case, and grouped code associated with some internal state in the other. Data-oriented design shifts the perspective of programming from objects to the data itself: The type of the data, how it is laid out in memory, and how it will be read and processed in the game.&quot;
This can be thought of as <b>particle-driven programming</b> (Llopis, 2009). </p>
<h3 id="clearing-up-confusion">Clearing up confusion</h3>
<p>&quot;A data-driven game is usually a game that exposes a large amount of functionality outside of code and lets the data determine the behavior of the game.&quot; This is orthogonal to data-oriented and so this is applicable to any type of programming approach (Llopis, 2009).</p>
<h2 id="ideal-data">Ideal data</h2>
<p>What&#39;s the format?
The data is in a format that can be used with the least amount of effort; the format is identical with the output under ideal circumstances. 
Processing is therefore limited to copying that information. </p>
<p><b> Large blocks of contiguous, homogenous data that is processed sequentially </b> because this goes along with the general goal of minimizing transformations. This can be baked during asset-building. </p>
<p>Consider
<img src='http://gamesfromwithin.com/wp-content/uploads/2009/12/oo_design.png'> 
versus
<img src='http://gamesfromwithin.com/wp-content/uploads/2009/12/do_design1.png'></p>
<h2 id="this-removes-trees-inheritence-containment-or-message-passing-trees-">This removes trees: inheritence, containment, or message-passing trees.</h2>
<h1 id="how">how</h1>
<ol>
<li>Break down each object into different components, </li>
<li>Group the components of the same type together in memory regardless of what object they came from</li>
</ol>
<h1 id="why-how">why-how</h1>
<p>OOP relies on one object but in complex state machines there are rarely singular instances of objects.</p>
<p>#advantages </p>
<h2 id="parallelization">parallelization</h2>
<p>-&gt; Consider the tedious task of parallelizing object-oriented code. It is error-prone due to sometimes confusing synchronization tasks (meant to halt concurrency at specific data; this causes idling until it has been debugged).
In data-oriented design, this is a much simpler process: data is input, a small function is assigned to process it and return output. That transformation can easily be taken and split among multiple threads with minimal synchronization to account for. (This can even be completed on the processor&#39;s local memory). </p>
<h2 id="cache-utilization">cache utilization</h2>
<p>-&gt; A codebase that is data-oriented is very efficient in its use of the instruction cache because the same code is executed repeatedly. 
-&gt; If the data is layed out in large, contiguous blocks, the data can be processed sequentially which results in impeccable cache utility, which translates into performance. 
-&gt; This is much simpler than re-writing C in assembly. </p>
<p>&quot;Remember that all a game does is transform some data (assets, inputs, state) into some other data (graphics commands, new game states). By keeping in mind that flow of data, we can make higher-level, more intelligent decisions based on how the data is transformed, and how it is used. That kind of optimization can be extremely difficult and time- consuming to implement with more traditional OOP methods.&quot;</p>
<h2 id="modularity">modularity</h2>
<p>-&gt; The tendency is to write small functions because they will usually be needed for transformation. 
-&gt; Lots of leaf functions/subroutines without many dependencies; this makes the comprehension and alteration of the code very easy. </p>
<h2 id="testing">testing</h2>
<p>-&gt; Testing is a simple process of calling transform functions and checking output data, as opposed to investigation into potentially dense structures in memory. </p>
<p>#disadvantages 
1) different from what people use or what they&#39;re taught in school; the way the programmer has to conceptualize their craft has to change fundamentally 
2) it can be tough to interface with existing code bases since it&#39;s a relatively novel approach across most work environments </p>
<p>#application 
1) work backwards
-navigation
-animations
-collisions</p>
<p>2) identify data inputs required by the system
3) identify data outputs required by the system
e.g.  in animation: 
input = skeletons, base poses, animation data, and current state 
output = new set of poses and updated state(data generated by animations)</p>
<p>4)classify input data on how it&#39;s used:
-read-only
-read-write
-write-only
this helps guide decisions about where to store it and when to process it depending on dependencies from other parts of the program</p>
<p>&quot;
At this point, stop thinking of the data required for a single operation, and think in terms of applying it to dozens or hundreds of entries. We no longer have one skeleton, one base pose, and a current state, and instead we have a block of each of those types with many instances in each of the blocks.</p>
<p>Think very carefully how the data is used during the transformation process from input to output. You might realize that you need to scan a particular field in a structure to perform a pass on the data, and then you need to use the results to do another pass. In that case, it might make more sense to split that initial field into a separate block of memory that can be processed independently, allowing for better cache utilization and potential parallelization. Or maybe you need to vectorize some part of the code, which requires fetching data from different locations to put it in the same vector register. In that case, that data can be stored contiguously so vector operations can be applied directly, without any extra transformations.</p>
<p>Now you should have a very good understanding of your data. Writing the code to transform it is going to be much simpler. It’s like writing code by filling in the blanks. You’ll even be pleasantly surprised to realize that the code is much simpler and smaller than you thought in the first place, compared to what the equivalent OOP code would have been.</p>
<p>If you think back about most of the topics we’ve covered in this column over the last year, you’ll see that they were all leading toward this type of design. Now it’s the time to be careful about how the data is aligned (Dec 2008 and Jan 2009), to bake data directly into an input format that you can use efficiently (Oct and Nov 2008), or to use non- pointer references between data blocks so they can be easily relocated (Sept 2009).
Is There Room For OOP?</p>
<p>Does this mean that OOP is useless and you should never apply it in your programs? I’m not quite ready to say that. Thinking in terms of objects is not detrimental when there is only one of each object (a graphics device, a log manager, etc) although in that case you might as well write it with simpler C-style functions and file-level static data. Even in that situation, it’s still important that those objects are designed around transforming data.</p>
<p>Another situation where I still find myself using OOP is GUI systems. Maybe it’s because you’re working with a system that is already designed in an object-oriented way, or maybe it’s because performance and complexity are not crucial factors with GUI code. In any case, I much prefer GUI APIs that are light on inheritance and use containment as much as possible (Cocoa and CocoaTouch are good examples of this). It’s very possible that a data-oriented GUI system could be written for games that would be a pleasure to work with, but I haven’t seen one yet.</p>
<p>Finally, there’s nothing stopping you from still having a mental picture of objects if that’s the way you like to think about the game. It’s just that the enemy entity won’t be all in the same physical location in memory. Instead, it will be split up into smaller subcomponents, each one forming part of a larger data table of similar components.</p>
<p>Data-oriented design is a bit of a departure from traditional programming approaches, but by always thinking about the data and how it needs to be transformed, you’ll be able to reap huge benefits both in terms of performance and ease of development.
&quot;</p><br><br><br><br> <h1>Beginning of Caruth</h1>
<p>&quot;Software is getting slower more rapidly than hardware becomes faster&quot;
Nilaus Wirth <em> A Plea for Lean Software </em> (1995)
<a href='https://cr.yp.to/bib/1995/wirth.pdf'>Link</a>
He also wrote <em>Algorithms + Data Structures = Programs</em></p>
<p>Steve Jobs initiated the centrality of mobile platforms and a newly crucial concern: batteries.
In contrast with the power-efficient instructions myth. Instead we must &quot;race to sleep&quot; through code that runs faster to achieve stasis. </p>
<p>Compute/watt is central to data-center operations. </p>
<p>Side note: Java is faster in consideration for throughput for long-term processing and garbage-collection because of optimization with JVM. </p>
<p>Caruth&#39;s thesis is about two points: 1) the centrality of <em>efficiency</em> through algorithms and 2) <em>performance</em> through data structures.</p>
<h3 id="definition-of-efficiency">definition of efficiency</h3>
<p><b>Efficiency</b>: how much work is required by a task. One can do this through doing less work; an efficient program is one that does the minimum amount of work that a task requires. </p>
<p>We should strive for the physical limit for how fast something can be achieved on the hardware.</p>
<p>Namely, each core should be used. </p>
<h1 id="efficiency-through-algorithms">Efficiency through algorithms</h1>
<h3 id="example-is-sub-string-searching-from-most-work-to-least-work">Example is sub-string searching: from most work to least work</h3>
<p>  1) Initially: O(n^2): looping over string continuously 
  2) Then: Knuth-Morris-Pratt: loops over substring and skips ahead 
  3) Finally: Boyer Moore: use the end of the string </p>
<h2 id="simple-examples-of-systemic-minor-mistakes-that-a-profiler-will-never-pick-these-up-">Simple examples of systemic minor mistakes that a profiler will never pick these up:</h2>
<h3 id="simple-algorithmic-hiccups">Simple algorithmic hiccups</h3>
<h4 id="example-1">Example 1</h4>
<pre><code><span class="hljs-built_in">std</span>::<span class="hljs-built_in">vector</span>&lt;X&gt;  f(<span class="hljs-keyword">int</span> n){
    <span class="hljs-built_in">std</span>::<span class="hljs-built_in">vector</span>&lt;X&gt; result;
    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i =<span class="hljs-number">0</span> ; i &lt; n; ++i)
        result.push_back(X(...));   <span class="hljs-comment">//don't need to allocate memory here </span>
    <span class="hljs-keyword">return</span> result;
}
</code></pre><p>to: </p>
<pre><code><span class="hljs-built_in">std</span>::<span class="hljs-built_in">vector</span>&lt;X&gt;  f(<span class="hljs-keyword">int</span> n){
    <span class="hljs-built_in">std</span>::<span class="hljs-built_in">vector</span>&lt;X&gt; result;
    result.reserve(n);             <span class="hljs-comment">//reserve it here </span>
    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i =<span class="hljs-number">0</span> ; i &lt; n; ++i)
        result.push_back(X(...)); 
    <span class="hljs-keyword">return</span> result;
}
</code></pre><h4 id="example-2">Example 2</h4>
<pre><code>Unordered <span class="hljs-built_in">map</span> repeats the same result <span class="hljs-number">4</span> times needlessly:
(This default constructs <span class="hljs-keyword">and</span> <span class="hljs-keyword">then</span> inserts:)

X *getX(<span class="hljs-built_in">std</span>::<span class="hljs-built_in">string</span> <span class="hljs-built_in">key</span>,
        <span class="hljs-built_in">std</span>::unordered_map&lt;<span class="hljs-built_in">std</span>::<span class="hljs-built_in">string</span>, 
        <span class="hljs-built_in">std</span>::unique_ptr&lt;X&gt;&gt; &amp;cache){
    <span class="hljs-keyword">if</span> (cache[<span class="hljs-built_in">key</span>])
        <span class="hljs-built_in">return</span> cache[<span class="hljs-built_in">key</span>].<span class="hljs-built_in">get</span>();

    cache[<span class="hljs-built_in">key</span>] = <span class="hljs-built_in">std</span>::make_unique&lt;X&gt;(...);
    <span class="hljs-built_in">return</span> cache[<span class="hljs-built_in">key</span>].<span class="hljs-built_in">get</span>();
}
</code></pre><p>to:</p>
<pre><code>X *getX(<span class="hljs-symbol">std:</span><span class="hljs-symbol">:string</span> key,
        <span class="hljs-symbol">std:</span><span class="hljs-symbol">:unordered_map&lt;std</span><span class="hljs-symbol">:</span><span class="hljs-symbol">:string</span>, 
        <span class="hljs-symbol">std:</span><span class="hljs-symbol">:unique_ptr&lt;X&gt;&gt;</span> &amp;cache){
    <span class="hljs-symbol">std:</span><span class="hljs-symbol">:unique_ptr&lt;X&gt;</span> &amp;entry = cache[key];                     <span class="hljs-regexp">//simple</span> fix
    if (cache[key])
        <span class="hljs-keyword">return</span> cache[key].get();
    cache[key] = <span class="hljs-symbol">std:</span><span class="hljs-symbol">:make_unique&lt;X&gt;</span>(...);
    <span class="hljs-keyword">return</span> cache[key].get();
}
</code></pre><p>Side note: input parameters can be affected -- pointer in because its origin can be unknown </p>
<h1 id="performance-through-data-structures-just-say-no-to-linked-lists-">Performance through data structures / &quot;Just say no to linked lists&quot;</h1>
<h2 id="a-quick-look-at-latency">A quick look at latency</h2>
<p>Context: 1billion cycles/second; 12+ cores per socket, 3+ execution ports per core</p>
<pre><code>&gt;: <span class="hljs-number">36</span> billions per <span class="hljs-keyword">second</span> are possible (<span class="hljs-keyword">but</span> most <span class="hljs-keyword">of</span> <span class="hljs-keyword">that</span> <span class="hljs-built_in">time</span> <span class="hljs-keyword">is</span> waiting <span class="hljs-keyword">for</span> data)

&gt;: We need faster memory <span class="hljs-keyword">but</span> <span class="hljs-keyword">until</span> <span class="hljs-keyword">then</span> <span class="hljs-keyword">it</span>'s instructive <span class="hljs-keyword">to</span> consider <span class="hljs-keyword">the</span> hierarchical cache system <span class="hljs-keyword">on</span> <span class="hljs-keyword">the</span> CPU:
</code></pre><p>(Diagram by Jeff Dean)</p>
<p>One cycle on a 3 GHz processor =                             1 ns
L1 cache reference =                                              0.5 ns
Branch mispredict                                                  5 ns 
L2 cache reference                                             7 ns / 14x L1 cache
Mutex lock/unlock                                                25 ns
Main memory reference                                        100 ns /20x L2, 200x L1
Compress 1k bytes with Snappy                                 3k ns
Send 1k bytes over 1 Gbps network                            10k ns / 0.01ms
Read 4k randomly from SSD                                    150k ns / 0.15 ms<br>Read 1 MB sequentially from memory                             250k ns / 0.25 ms
Round trip within same data-center                            500k ns / 0.5 ms
Read 1 MB sequentially from SSD                            1mil ns / 1 ms / 4x memory
Disk seek                                                        10mil ns / 10 ms 
Read 1 MB sequentially from HDD                            20 mil ns / 20 ms
Send packet CA-&gt;Netherlands-&gt;CA                             150 mil ns / 150 ms</p>
<h3 id="std-list-which-is-a-doubly-linked-list">STD::List, which is a doubly-linked list</h3>
<p>-each node is separately allocated, which is awful because node is allocated randomly, leading to a tremendous amount of traversed lookups between pointers.</p>
<p>-all traversal operations chase pointers to totally new memory</p>
<p>-in most cases, every step is a cache miss:
    Cache Misses:
            Each traversal causes a cache miss and so a safe 
            assumption is that for every movement between
            nodes you have a 1% chance of being in L1 and 
            maybe a 10% chance of being in L2. Otherwise 
            it&#39;s safe to assume it will be in main memory (80-90%). </p>
<p>-only use this when you rarely traverse the list but frequently update it </p>
<blockquote>
<p>Critique of Iterator Invalidation</p>
</blockquote>
<h3 id="therefore-just-use-std-vector">Therefore just use STD::Vector</h3>
<pre><code>&gt;: Knowing <span class="hljs-built_in">number</span> <span class="hljs-keyword">of</span> <span class="hljs-keyword">items</span> <span class="hljs-built_in">to</span> be allocated <span class="hljs-built_in">to</span> <span class="hljs-keyword">a</span> defined 
<span class="hljs-built_in">upper</span> limit <span class="hljs-keyword">and</span>/<span class="hljs-keyword">or</span> is used <span class="hljs-keyword">for</span> <span class="hljs-keyword">a</span> brief period, just remove 
<span class="hljs-keyword">items</span> <span class="hljs-built_in">from</span> <span class="hljs-keyword">the</span> front. One can <span class="hljs-built_in">add</span> <span class="hljs-built_in">to</span> <span class="hljs-keyword">the</span> vector indefinitely 
<span class="hljs-keyword">and</span> keep track <span class="hljs-keyword">of</span> <span class="hljs-keyword">the</span> front <span class="hljs-keyword">with</span> <span class="hljs-keyword">an</span> index. 
</code></pre><h3 id="vs-stacks-queues-and-maps-">vs Stacks, Queues, and Maps?</h3>
<h4 id="vs-stacks">vs Stacks</h4>
<pre><code>&gt;Knowing <span class="hljs-built_in">number</span> <span class="hljs-keyword">of</span> <span class="hljs-keyword">items</span> <span class="hljs-built_in">to</span> be allocated <span class="hljs-built_in">to</span> <span class="hljs-keyword">a</span> defined  
<span class="hljs-built_in">upper</span> limit <span class="hljs-keyword">and</span>/<span class="hljs-keyword">or</span> is used <span class="hljs-keyword">for</span> <span class="hljs-keyword">a</span> brief period, just remove 
<span class="hljs-keyword">items</span> <span class="hljs-built_in">from</span> <span class="hljs-keyword">the</span> front. One can <span class="hljs-built_in">add</span> <span class="hljs-built_in">to</span> <span class="hljs-keyword">the</span> vector 
indefinitely <span class="hljs-keyword">and</span> keep track <span class="hljs-keyword">of</span> <span class="hljs-keyword">the</span> <span class="hljs-function"><span class="hljs-keyword">end</span> <span class="hljs-title">with</span> <span class="hljs-title">an</span> <span class="hljs-title">index</span>. </span>
</code></pre><h4 id="vs-queues">vs Queues</h4>
<pre><code>&gt;Knowing <span class="hljs-built_in">number</span> <span class="hljs-keyword">of</span> <span class="hljs-keyword">items</span> <span class="hljs-built_in">to</span> be allocated <span class="hljs-built_in">to</span> <span class="hljs-keyword">a</span> defined 
<span class="hljs-built_in">upper</span> limit <span class="hljs-keyword">and</span>/<span class="hljs-keyword">or</span> is used <span class="hljs-keyword">for</span> <span class="hljs-keyword">a</span> brief period, just remove 
<span class="hljs-keyword">items</span> <span class="hljs-built_in">from</span> <span class="hljs-keyword">the</span> front. One can <span class="hljs-built_in">add</span> <span class="hljs-built_in">to</span> <span class="hljs-keyword">the</span> vector 
indefinitely <span class="hljs-keyword">and</span> keep track <span class="hljs-keyword">of</span> <span class="hljs-keyword">the</span> front <span class="hljs-keyword">with</span> <span class="hljs-keyword">an</span> index. 
</code></pre><p>[side-noted]</p>
<h4 id="vs-maps-proper-hash-table-design">vs Maps &gt;&gt; proper hash table design</h4>
<p>[&quot;STD::Map solves no problems.&quot;]
It&#39;s a linked list where non-traversal elements are removed</p>
<pre><code>&gt;: STD:Unordered_Map requires buckets <span class="hljs-keyword">of</span> key-<span class="hljs-built_in">value</span> pairs <span class="hljs-keyword">for</span> <span class="hljs-keyword">each</span> hash.

&gt;: Buckets are linked lists 

&gt;: Cache misses are incredibly likely
</code></pre><p>a. Instead of buckets, use open addressing into a table of key-value pairs. 
b. A table can be stored as contiguous range of memory. 
c. Use local/linear probing on collisions to find open slot in the same cache line.
    <a href="https://en.wikipedia.org/wiki/Linear_probing">https://en.wikipedia.org/wiki/Linear_probing</a>
d. Keep both key and values small.</p>
<h1 id="side-notes">Side notes</h1>
<h3 id="in-practice-both-algorithms-and-structures-are-tightly-related">In practice, both algorithms and structures are tightly related</h3>
<p>Structures <em>typically</em> inform algorithms but they&#39;re meant to be balanced.</p>
<p>[Side-ish notes]
-Bubble sort is great for small data sets (under 64, if they&#39;re numbers especially)
-Cuckoo hashing: backup hash algorithm can be algorithmically linear but every probe is a cache miss</p>
